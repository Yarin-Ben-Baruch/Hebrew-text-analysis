{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 - Competitive Assignment\n",
    "An explanation this assignment could be found in the .pdf explanation document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preceding Step - import modules (packages)\n",
    "This step is necessary in order to use external modules (packages). <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Id : 209040757\n",
    "# Name : Yarin Ben Baruch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for reading and writing (input & output) files:\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add whatever imports you need\n",
    "# YOUR CODE HERE\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "# *** KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# *** Decision Tree; Random Forest\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "# *** Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "# *** SVM classifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input files\n",
    "Reading input files for train annotated corpus (raw text data) corpus and for the test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = '.' + os.sep + 'input' + os.sep + 'annotated_corpus_for_train.xlsx'\n",
    "test_filename  = '.' + os.sep + 'input' + os.sep + 'corpus_for_test.xlsx'\n",
    "\n",
    "\n",
    "df_train = pd.read_excel(train_filename, 'corpus', index_col=None, na_values=['NA'])\n",
    "df_test  = pd.read_excel(test_filename,  'corpus', index_col=None, na_values=['NA'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your implementation:\n",
    "Write your code solution in the following code-cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "def train(X,y,rand):\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state= rand)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "#Regular expression on dataframe \n",
    "def regOnDate(df):\n",
    "    \n",
    "    for i in df.index:\n",
    "        \n",
    "        df.iloc[i,0] = re.sub(r'\\W',' ',str(df.iloc[i,0]))# החלפת תווים מיוחדים\n",
    "        df.iloc[i,0] = re.sub(r'\\d',' ',str(df.iloc[i,0]))# החלפה מספרים\n",
    "        df.iloc[i,0] = re.sub(r'\\s\\w\\s',' ',df.iloc[i,0]) # החלפה אות בודדת\n",
    "\n",
    "        \n",
    "    return df\n",
    "\n",
    "#regular expression on dataframe for the test\n",
    "def regOnDateTest(df):\n",
    "    \n",
    "    for i in df.index:\n",
    "        \n",
    "        df.iloc[i,1] = re.sub(r'\\W',' ',str(df.iloc[i,1]))# החלפת תווים מיוחדים\n",
    "        df.iloc[i,1] = re.sub(r'\\d',' ',str(df.iloc[i,1]))# החלפה מספרים\n",
    "        df.iloc[i,1] = re.sub(r'\\s\\w\\s',' ',df.iloc[i,1]) # החלפה אות בודדת\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "# F1 - avg women and men\n",
    "def f1Avg(y_test, y_pred):\n",
    "    \n",
    "    conf_mat = metrics.confusion_matrix(y_test, y_pred) #\n",
    "\n",
    "    TP = conf_mat[0][0]\n",
    "    FP = conf_mat[0][1]\n",
    "    FN = conf_mat[1][0]\n",
    "    TN = conf_mat[1][1]\n",
    "    \n",
    "    \n",
    "    precision_m = TN / (TN + FN)\n",
    "    recall_m = TN / (TN + FP)\n",
    "\n",
    "    precision_f = TP / (TP + FP)\n",
    "    recall_f = TP / (TP + FN)\n",
    "\n",
    "\n",
    "    F1_f = 2 * (precision_f * recall_f) / (precision_f + recall_f)\n",
    "    F1_m = 2 * (precision_m * recall_m) / (precision_m + recall_m)\n",
    "\n",
    "    F1_avg = (F1_f + F1_m) / 2\n",
    "    \n",
    "    return F1_avg\n",
    "\n",
    "\n",
    "\n",
    "# Common word\n",
    "def Words(df,num):\n",
    "    \n",
    "    words = []\n",
    "    \n",
    "    for i in df.index:\n",
    "        split = str(df.iloc[i, 0]).split() # Split the data\n",
    "        words = words + split # Add to list\n",
    "\n",
    "        \n",
    "    counter = Counter(words)\n",
    "\n",
    "    commonWords = [key for key, _ in counter.most_common(num)] \n",
    "    \n",
    "    \n",
    "    return commonWords # Return the words list .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = regOnDate(df_train) \n",
    "\n",
    "X = df_train['story']\n",
    "y = df_train['gender']\n",
    "\n",
    "\n",
    "y = y.replace('m', 1)\n",
    "y = y.replace('f', 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML - TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train(X,y,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for the successful model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(max_features=6000, ngram_range=(1, 2),\n",
       "                                 stop_words=['את', 'לא', 'של', 'על', 'היה',\n",
       "                                             'עם', 'שלי', 'לי', 'אני', 'כל',\n",
       "                                             'זה', 'לאחר', 'מאוד', 'הוא', 'מה',\n",
       "                                             'אבל', 'גם', 'שאני', 'כי', 'הייתה',\n",
       "                                             'כמה', 'אחד', 'יותר', 'לנו', 'יום',\n",
       "                                             'אחרי', 'אותו', 'כבר', 'אותי',\n",
       "                                             'שלא', ...])),\n",
       "                ('clf', RandomForestClassifier(random_state=1))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_RF = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words= Words(df_train,80) , ngram_range=(1,2), max_features=6000)),\n",
    "    ('clf', RandomForestClassifier(random_state=1))])\n",
    "\n",
    "\n",
    "text_clf_RF.fit(x_train, y_train)\n",
    "predicted_train = text_clf_RF.predict(x_test)\n",
    "f1Avg(y_test, predicted_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', TfidfVectorizer(max_features=7500)),\n",
       "                ('clf', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6137566137566137"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_KNN = Pipeline([\n",
    "    ('vect', TfidfVectorizer(max_features=7500)),\n",
    "    ('clf', KNeighborsClassifier(n_neighbors= 5))])\n",
    "\n",
    "text_clf_KNN.fit(x_train, y_train)\n",
    "predicted_train = text_clf_KNN.predict(x_test)\n",
    "f1Avg(y_test, predicted_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(max_features=6000,\n",
       "                                 stop_words=['את', 'לא', 'של', 'על', 'היה',\n",
       "                                             'עם', 'שלי', 'לי', 'אני', 'כל',\n",
       "                                             'זה', 'לאחר', 'מאוד', 'הוא', 'מה',\n",
       "                                             'אבל', 'גם', 'שאני', 'כי', 'הייתה',\n",
       "                                             'כמה', 'אחד', 'יותר', 'לנו', 'יום',\n",
       "                                             'אחרי', 'אותו', 'כבר', 'אותי',\n",
       "                                             'שלא', ...])),\n",
       "                ('clf', DecisionTreeClassifier(random_state=40))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6137566137566137"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_DT = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features=6000,stop_words= Words(df_train,33))),\n",
    "    ('clf', DecisionTreeClassifier(random_state=40))])\n",
    "\n",
    "\n",
    "text_clf_DT.fit(x_train, y_train)\n",
    "predicted_train = text_clf_DT.predict(x_test)\n",
    "f1Avg(y_test, predicted_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(max_features=2000, ngram_range=(1, 4))),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7598684210526316"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_NB = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features= 2000, ngram_range=(1,4))),\n",
    "    ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf_NB.fit(x_train, y_train)\n",
    "predicted_train = text_clf_NB.predict(x_test)\n",
    "f1Avg(y_test, predicted_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', TfidfVectorizer(max_features=9000)), ('clf', SVC())])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_SVC = Pipeline([\n",
    "    ('vect', TfidfVectorizer(max_features=9000)),\n",
    "    ('clf', SVC())])\n",
    "\n",
    "\n",
    "\n",
    "text_clf_SVC.fit(x_train, y_train)\n",
    "predicted_train = text_clf_SVC.predict(x_test)\n",
    "f1Avg(y_test, predicted_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(max_features=6000, ngram_range=(1, 6))),\n",
       "                ('clf', MLPClassifier(alpha=1, max_iter=1000))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6256410256410255"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_MLP = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,6), max_features=6000)),\n",
    "    ('clf', MLPClassifier(alpha=1, max_iter=1000))])\n",
    "\n",
    "\n",
    "text_clf_MLP.fit(x_train, y_train)\n",
    "predicted_train = text_clf_MLP.predict(x_test)\n",
    "f1Avg(y_test, predicted_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(max_features=5500, ngram_range=(1, 2),\n",
       "                                 stop_words=['את', 'לא', 'של', 'על', 'היה',\n",
       "                                             'עם', 'שלי', 'לי', 'אני', 'כל',\n",
       "                                             'זה', 'לאחר', 'מאוד', 'הוא', 'מה',\n",
       "                                             'אבל', 'גם', 'שאני', 'כי', 'הייתה',\n",
       "                                             'כמה', 'אחד', 'יותר', 'לנו', 'יום',\n",
       "                                             'אחרי', 'אותו', 'כבר', 'אותי',\n",
       "                                             'שלא', ...])),\n",
       "                ('clf', AdaBoostClassifier())])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6313131313131313"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_AdaBoost = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words=Words(df_train,74),max_features=5500,ngram_range=(1,2))),\n",
    "    ('clf', AdaBoostClassifier())])\n",
    "\n",
    "\n",
    "text_clf_AdaBoost.fit(x_train, y_train)\n",
    "predicted_train = text_clf_AdaBoost.predict(x_test)\n",
    "f1Avg(y_test, predicted_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model chosen: Naive Bayes\n",
    "## Grade : 0.759"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = regOnDateTest(df_test) \n",
    "\n",
    "X_test = df_test['story']\n",
    "\n",
    "predDfTest = text_clf_NB.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_test.copy()\n",
    "\n",
    "for i in range(0,len(test['test_example_id'])):\n",
    "    test['test_example_id'][i] = predDfTest[i] \n",
    "    \n",
    "\n",
    "    \n",
    "test['test_example_id'] = test['test_example_id'].replace(1,'m')\n",
    "test['test_example_id'] = test['test_example_id'].replace(0,'f')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to csv\n",
    "After you're done save your output to the 'classification_results.csv' csv file.<br/>\n",
    "We assume that the dataframe with your results contain the following columns:\n",
    "* column 1 (left column): 'test_example_id'  - the same id associated to each of the test stories to be predicted.\n",
    "* column 2 (right column): 'predicted_category' - the predicted gender value for each of the associated story. \n",
    "\n",
    "Assuming your predicted values are in the `df_predicted` dataframe, you should save you're results as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted = pd.DataFrame(columns = ['test_example_id','predicted_category'])\n",
    "\n",
    "df_predicted['test_example_id'] = df_test['test_example_id']\n",
    "df_predicted['predicted_category'] = test['test_example_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted.to_csv('classification_results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
